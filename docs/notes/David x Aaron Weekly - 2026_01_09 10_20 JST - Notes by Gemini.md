Jan 9, 2026

## David x Aaron Weekly

Invited [Aaron Keith Hilton](mailto:aaron@steampunk.digital) [David Clement](mailto:xclement@gmail.com)

Attachments [David x Aaron Weekly](https://www.google.com/calendar/event?eid=MTY2cDdubnJxN3VzYm80NXRqZ2IzMmxscGhfMjAyNjAxMDlUMDEwMDAwWiBhYXJvbkBzdGVhbXB1bmsuZGlnaXRhbA) [Notes by Gemini](https://docs.google.com/document/d/1lHvXITovYSZseLk1ZvtsV-_uWmOGWvp-ca0tOoxNTcQ/edit?usp=meet_tnfm_calendar) 

Meeting records [Transcript](?tab=t.bgy4l4vamqf0) 

### Summary

Aaron Hilton and David Clement discussed their technical week, with David Clement praising Microsoft Entra for its efficient identity and access management, while Aaron Hilton suggested using voice activation with a model like SAM audio to manage real-time interaction in an AR workflow. The speakers concluded that the pipeline for descriptive voice input generating a 3D object using SAM 3D is "totally solvable" and agreed to use the Meta Quest 3 and a web stack with a Flask backend for initial development of the "digital dojo" concept, a scalable asymmetric two-person VR/AR experience. Key talking points included David Clement’s interest in Entra's security benefits and cost model, Aaron Hilton's critique of the Apple Vision Pro and presentation of Brilliant Labs as an alternative, and their joint exploration of Gaussian Splats as a performant way to render dynamic 3D worlds.

### Details

*Notes Length: Standard*

* **Reflecting on the Past Week and Entra Discussion** Aaron Hilton reported having an interesting and busy week, including dealing with servers going down, which they suspected might be related to WordPress. David Clement expressed satisfaction with their "Intra" experience, which is Microsoft's identity and access management solution, describing it as a well-done platform that handles user authentication and enterprise security ([00:00:00](?tab=t.bgy4l4vamqf0#heading=h.j8cf1bfbxmrd)). David Clement clarified that Entra is a security layer that is tightly coupled with server access management but not server operation, and they praised its efficiency and ability to manage security in a one-stop shop ([00:01:32](?tab=t.bgy4l4vamqf0#heading=h.fhnyzpviif0k)).

* **Testing Environment and Collaborative Goals** David Clement questioned if Aaron Hilton had reflected on their previous conversation about creating a test environment for trying out new things and efficiently sharing work ([00:02:50](?tab=t.bgy4l4vamqf0#heading=h.qzgjjsw3uv04)). David Clement emphasized the goal of creating a loop for mutual learning and using each other's work, suggesting a lack of a current business use case but a strong interest in putting effort into the project ([00:03:41](?tab=t.bgy4l4vamqf0#heading=h.16ca3e64vps8)).

* **Exploring Voice Activity Detection (VAD) and SAM 3D Integration** The conversation turned to the "VAD" or Voice Activity Detector, which David Clement had sent to Aaron Hilton, leading to an acknowledgement that the concept looked cool and the model seemed lightweight and strong ([00:03:41](?tab=t.bgy4l4vamqf0#heading=h.16ca3e64vps8)). David Clement then proposed a workflow involving augmented reality (AR) glasses (Quest 3\) where a user looks at an object and, with guidance, can use the SAM 3D technology to essentially capture and interact with the object ([00:04:39](?tab=t.bgy4l4vamqf0#heading=h.62gw36frxg8l)).

* **Advanced Audio Activation and Real-Time Interaction** Aaron Hilton mentioned the limitation of eye-tracking in current display classes and suggested using voice activation with a model like SAM audio, which is open source and designed for real-time use, even in noisy environments ([00:05:34](?tab=t.bgy4l4vamqf0#heading=h.7l1m51715qun)). Aaron Hilton explained that this model could isolate David Clement's voice with minimal training and eliminate the need for a separate voice activation detector model. David Clement was interested in the utility of the approach, aiming for a "holiday" experience where speaking into the ether makes things appear ([00:06:26](?tab=t.bgy4l4vamqf0#heading=h.3swl97n2b2jo)).

* **Pipeline for Descriptive Voice Input and Backend Setup** The speakers concluded that the whole pipeline, from descriptive voice input to generating a 3D object using SAM 3D, is totally solvable ([00:07:15](?tab=t.bgy4l4vamqf0#heading=h.qnhjxfuyugbb)). For implementation, David Clement suggested using Flask, a Python-based web backend, as a "rock solid" choice for a federated data access layer that is dumb and simple, with all the smarts residing on the client side ([00:07:58](?tab=t.bgy4l4vamqf0#heading=h.zecb90idvw73)). Aaron Hilton agreed on the convenience of keeping functionality in the Python environment, noting that they think in Python due to its prevalence in machine learning ([00:08:55](?tab=t.bgy4l4vamqf0#heading=h.515lpmwuw0x4)).

* **Source Control and Dependency Management** Aaron Hilton noted the "crazy dependency hell" often encountered with JavaScript, a problem David Clement mitigates by using very standard, "center of the road" tools and writing their own shaders ([00:09:40](?tab=t.bgy4l4vamqf0#heading=h.1kpsivu664yk)). When discussing version control, both speakers expressed a dislike for Git's merging capabilities but acknowledged its ubiquitous use due to being free and widely adopted, with David Clement using GitHub and Aaron Hilton preferring the Fork GUI client ([00:26:06](?tab=t.bgy4l4vamqf0#heading=h.bw4tnttqfbf9)). Aaron Hilton offered to set up a paid GitHub repository for collaboration, with the suggestion of using a monorepo structure ([00:27:35](?tab=t.bgy4l4vamqf0#heading=h.c4kyh7r5tysz)) ([00:29:16](?tab=t.bgy4l4vamqf0#heading=h.r8chi6d6a4pu)).

* **Identifying the Correct AR Display Hardware** The discussion shifted to the necessary hardware, with David Clement clarifying that the Meta Glasses they initially saw only had a camera and headphones, which led to frustration when trying to find a display-enabled device. Aaron Hilton clarified the existence of the "Meta displays," which feature a color heads-up display, confirming that this was the AR functionality David Clement was seeking ([00:13:36](?tab=t.bgy4l4vamqf0#heading=h.lj5gukabldh8)).

* **Critique of Apple Vision Pro** Aaron Hilton gave a negative assessment of the Apple Vision Pro, calling it a niche device that is too heavy, overbuilt, and unlikely to achieve critical mass among app developers due to its high price and weight ([00:14:25](?tab=t.bgy4l4vamqf0#heading=h.sog2aw6oqqov)). David Clement agreed, also noting that even the camera-only Meta glasses felt heavy and clunky ([00:16:29](?tab=t.bgy4l4vamqf0#heading=h.8ti5y2rx9lxz)).

* **Exploring Brilliant Labs as an Alternative** David Clement expressed interest in focusing on AR, potentially even a "decent phone-based AR experience" as "good enough". Aaron Hilton presented their own current hardware, Brilliant Labs glasses, which feature a color display but are practically unusable due to poor optics and reflections ([00:17:14](?tab=t.bgy4l4vamqf0#heading=h.iaeooxgn6x5w)). However, Aaron Hilton noted that a company called Brilliant Soul has developed new web-driven, open-source firmware for the glasses, making them more useful by providing access to audio streams, accelerometer data, and camera images ([00:19:46](?tab=t.bgy4l4vamqf0#heading=h.y1znddzflgoo)).

* **Choosing the Meta Quest 3 for Initial Development** Aaron Hilton proposed using the Meta Quest 3 for initial development, running the AR experience with "pass through" locally on the headset ([00:21:51](?tab=t.bgy4l4vamqf0#heading=h.akaojdhcdwnb)). David Clement agreed that the Quest 3 provides a sensible starting point for a largely AR experience (99% AR, 1% VR) using a web stack, potentially leveraging a personal hotspot for off-board processing ([00:22:25](?tab=t.bgy4l4vamqf0#heading=h.92fz68u4arli)). David Clement confirmed they would acquire the Quest 3, specifically the Quest 3 and not the cut-down Quest 3S, along with the recommended Bobo VR headstrap for better comfort ([00:30:39](?tab=t.bgy4l4vamqf0#heading=h.pw6wpu5p28hv)).

* **Discovering Dockling and AI Agent Flocks** Aaron Hilton introduced "Dockling," a tool for loading and extracting meaningful content from various file types to prepare it for AI indexing and use as context ([00:32:09](?tab=t.bgy4l4vamqf0#heading=h.sq8l6nxiwbub)). They also mentioned a friend, Nick, who is working on "Agent Flocks," an LLM agent system that uses multiple agents with different personalities to interact and validate information, aiming for truthful responses from small models, using Greek and English philosophical documentation as a test case ([00:34:22](?tab=t.bgy4l4vamqf0#heading=h.x09h3a9hsdtb)).

* **Conceptualizing the Digital Dojo** David Clement sought clarification on the "digital dojo" concept, initially recalling it as a performer fulfilling an audience's wish via a chatbot ([00:36:44](?tab=t.bgy4l4vamqf0#heading=h.pmjou54r08xp)). Aaron Hilton clarified the "digital dojo" as an asymmetric, two-person experience: the "Creator," who expresses ideas in plain language within a pure VR environment; and the "Maker," who is technically proficient, has "information overload," and uses their expertise to translate the Creator's ideas into the digital world ([00:37:54](?tab=t.bgy4l4vamqf0#heading=h.3jixmcjl6c7v)). The Maker communicates through presenting pixels (digital creations) rather than speech, though full fidelity communication (mixed reality or avatars) is possible ([00:40:13](?tab=t.bgy4l4vamqf0#heading=h.fe05lunw30eg)).

* **Scaling the Digital Dojo and its Real-World Applications** David Clement proposed scaling the digital dojo into a collective intelligence or community, rather than a one-to-one experience, which Aaron Hilton confirmed is where the concept could scale exponentially. Aaron Hilton illustrated this scaling with the example of building a dream house: a Creator provides a basic 3D reconstruction of a site, and a Maker (director/architect) coordinates specialists (e.g., plumbers) to generate detailed, procedurally generated elements like plumbing ([00:42:18](?tab=t.bgy4l4vamqf0#heading=h.argd5tr1wzow)). David Clement envisioned a scenario where a plumber would interact with a Claude-like system generating plumbing in a model and ordering parts using an AR headset ([00:45:37](?tab=t.bgy4l4vamqf0#heading=h.2q8o1v6rjewv)).

* **Entitlement and Asymmetric Digital Experiences** Aaron Hilton emphasized that the asymmetric nature of the digital dojo, where one person sees a subset of the overall environment, is a core challenge since most engines are built on full synchronization ([00:46:24](?tab=t.bgy4l4vamqf0#heading=h.9acyalax62zq)). David Clement referenced Microsoft Entra as a system that manages this complex space of entitlement and fine-grain security effectively for enterprise SAS ([00:47:34](?tab=t.bgy4l4vamqf0#heading=h.likpg3aeuvx7)). Aaron Hilton expressed two concerns about using Entra: reliance on a corporation's long-term implementation and the potential cost implications of scaling to thousands of users ([00:48:40](?tab=t.bgy4l4vamqf0#heading=h.3oljw7sy62w7)).

* **Entra's Pricing Model and Security Benefits** David Clement clarified that Entra is a tenant-based, not per-seat, system, showing their Azure resources bound to a tenant, which gives them Entra functionality for free when publishing enterprise applications ([00:49:42](?tab=t.bgy4l4vamqf0#heading=h.84sf2li5mnav)). David Clement touted Entra's ability to provide tokens for ultra-secure service publishing with minimal effort, handling all authentication, two-factor authentication, and privilege checking ([00:52:40](?tab=t.bgy4l4vamqf0#heading=h.x83mr0o5vawk)). David Clement maintained that a complete off-the-shelf system for identity and attribution is vital, citing Entra as an example of a strong, bulletproof mechanic, but noting that OAUTH 2 or a FOS stack would also work ([00:55:33](?tab=t.bgy4l4vamqf0#heading=h.6n2a9t48k7us)).

* **Asymmetry and Session Identity** David Clement and Aaron Hilton discussed the concept of asymmetry within a system, which David Clement suggested is already handled by "entra" and could be utilized either by stealing patterns or using the code ([00:58:06](?tab=t.bgy4l4vamqf0#heading=h.8v8ey9dcrj1f)). Aaron Hilton explored the idea of session-based identity variations, an asymmetric hierarchy where individuals might have a dual identity and participate in multiple linked sessions simultaneously, similar to bubbles between two people. They likened this structure to the two asymmetric experiences provided by Uber—the consumer experience and the driver experience ([00:58:51](?tab=t.bgy4l4vamqf0#heading=h.nu32rkx1mr4t)) ([01:00:41](?tab=t.bgy4l4vamqf0#heading=h.5v31jhe8s90s)).

* **Generative AI and 3D Worlds** The conversation shifted to how AI technologies are evolving rapidly and the need for simple, common foundations for these elements to plug into ([01:01:35](?tab=t.bgy4l4vamqf0#heading=h.d276ebr4lj3h)). Aaron Hilton noted that while web pages provide a common foundation for text and images, they are limiting because they are stuck in a 2D domain and have not solved the structure of a 3D world. The speakers identified an interesting opportunity space for AI to generate dynamic 3D worlds quickly, suggesting a potential reboot on how these experiences are put together, leaning more into dynamic worlds and environments ([01:02:41](?tab=t.bgy4l4vamqf0#heading=h.zetnm7vl2i3)) ([01:06:32](?tab=t.bgy4l4vamqf0#heading=h.26wix1n4wcli)).

* **Gaussian Splats and 3D Rendering** Aaron Hilton introduced "Dreams" (PlayStation Dreams) by Media Molecule as a reference point for dynamic game engines that use a "splat-based" representation, similar to Gaussian splats, showing how far prior-generation technology had progressed. David Clement expressed interest in the efficiency of splats but questioned how they are generated fast enough, especially synthesizing them rather than relying only on capture data ([01:03:57](?tab=t.bgy4l4vamqf0#heading=h.pqfua5wvoa8y)) ([01:06:32](?tab=t.bgy4l4vamqf0#heading=h.26wix1n4wcli)). Aaron Hilton explained that Gaussian Splats offer a more believable representation due to the hemispherical harmonic representations of light, which correctly solves for illumination ([01:06:32](?tab=t.bgy4l4vamqf0#heading=h.26wix1n4wcli)).

* **Converting 3D Models to Splats** David Clement questioned the process of generating splats from an underlying mathematical model or converting a 3D model, as opposed to photogrammetric reconstruction ([01:07:38](?tab=t.bgy4l4vamqf0#heading=h.w8xd8hdrtc5d)). Aaron Hilton confirmed that converting a 3D model to splat representation is possible, noting that a BRDF (Bidirectional Reflectance Distribution Function) is a subset of the splat representation, allowing for conversion from a model to a splat cloud ([01:09:32](?tab=t.bgy4l4vamqf0#heading=h.qk1ollsp9rn2)). However, Aaron Hilton pointed out that a raw conversion would result in a "horrendously huge" data set, making efficiency a problem, which requires running optimization rules (merging and collapsing) on the collections of splats ([01:10:32](?tab=t.bgy4l4vamqf0#heading=h.rhxl4lfi96c4)).

* **Splat Streaming and Dynamic Worlds** The speakers discussed splat streaming as a necessary feature for scaling to different people's compute capabilities, referencing a Play Canvas LOD streaming feature ([01:11:53](?tab=t.bgy4l4vamqf0#heading=h.45ydqoxzs2h4)). David Clement desired a way to generate splats fast enough from a low-dimensional form, like a mathematical equation, to enable streaming of 3D detail and offer high-quality results on powerful computers while still providing a good result on less capable devices. They agreed that this points to a need for a compression idea and a codec with a very efficient kernel that could express an animated thing, outputting a high-density splat cloud upon decode, even if the original data is simple ([01:14:34](?tab=t.bgy4l4vamqf0#heading=h.cnsd5z7jghin)).

* **Next Steps and Wrap-up** David Clement confirmed that they need a technique to generate good-looking splats using a procedure, identifying this as the "big gap" in the content generator ([01:15:25](?tab=t.bgy4l4vamqf0#heading=h.mpat0p9sdr5i)). David Clement had to conclude the meeting but committed to looking at the links shared. Aaron Hilton proposed setting up a GitHub repository called "digital dojo sandbox" to start collaborating and exploring these ideas ([01:16:07](?tab=t.bgy4l4vamqf0#heading=h.dzdssuyat683)). David Clement agreed and offered to set up a FLOSS server if needed ([01:16:07](?tab=t.bgy4l4vamqf0#heading=h.dzdssuyat683)).

### Suggested next steps

- [ ] David Clement will check out the Brilliant Labs device as an interesting option for the project.  
- [ ] Aaron Hilton will set up a monorepo on GitHub for David Clement and Aaron Hilton to collaborate on the project.  
- [ ] David Clement will pick up a Meta Quest 3 headset and the Bobo VR headstrap for the project.  
- [ ] Aaron Hilton will send David Clement a link to the Sam audio (clip thing) which David Clement will get going right away.  
- [ ] David Clement and Aaron Hilton will use the Quest 3 headset for the project and run everything in the headset using the pass through feature to quickly get started on the AR experience.  
- [ ] Aaron Hilton will stand up a GitHub repo called digital dojo sandbox for the group to use as a play around space.  
- [ ] David Clement will set up a floss server if Aaron Hilton needs anything to stand up.  
- [ ] David Clement will study the link of the play canvas LOD streaming.

*You should review Gemini's notes to make sure they're accurate. [Get tips and learn how Gemini takes notes](https://support.google.com/meet/answer/14754931)*

*Please provide feedback about using Gemini to take notes in a [short survey.](https://google.qualtrics.com/jfe/form/SV_9vK3UZEaIQKKE7A?confid=9KGl-CjmvNI_0yu0WqaZDxIROAIIigIgABgECA&detailid=standard)*