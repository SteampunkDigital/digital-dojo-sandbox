Jan 16, 2026

## David x Aaron Weekly

Invited [Aaron Keith Hilton](mailto:aaron@steampunk.digital) [David Clement](mailto:xclement@gmail.com)

Attachments [David x Aaron Weekly](https://www.google.com/calendar/event?eid=MTY2cDdubnJxN3VzYm80NXRqZ2IzMmxscGhfMjAyNjAxMTZUMDEwMDAwWiBhYXJvbkBzdGVhbXB1bmsuZGlnaXRhbA) 

Meeting records [Transcript](?tab=t.l4sbz8sbdhyl) 

### Summary

David Clement and Aaron Hilton set up a public GitHub repository, with David Clement joining as a maintainer, and discussed the initial folder structure, including David Clement's suggestion of a "content" folder and Aaron Hilton's decision to simplify the structure. David Clement presented a refactored application demo focusing on video-to-reconstruction on a map using geolocation, and explained their standard use of a simple Flask server for prototypes.

The discussion then centered on generative AI input, where Aaron Hilton and David Clement considered using VGG backbones for encoding image inputs, and David Clement proposed a "generative world model" concept based on a non-cumulative, "forgetting" system where users virtually "walk" through the generated environment. Aaron Hilton shared technical approaches for world generation, including using diffusion models with Gaussian splat clouds and a spatial alignment pipeline, while David Clement outlined a generation loop diagram involving "context" feeding into a diffusion generator.

Further topics included control mechanisms for the diffusion generator using MCP endpoints, Aaron Hilton's suggestion of using a Segment Anything Model (SAM) for "isolation masks," and David Clement's proposal for a "context hierarchy" structured as a graph or DAG to enable granular refinement. They also discussed maintaining object persistence using Lauras (low-rank adaptation) for consistency, which Aaron Hilton confirmed serves as a base representation fed back as context, and David Clement introduced the theoretical framework of "nested causal niches."

Finally, David Clement and Aaron Hilton discussed building a "steerable diffusion generator that's constantly running," leading to Aaron Hilton introducing the concept of an "omnivoxal representation" (ooxals) as a scalable, sparse compression of active spatial context that incorporates geometry and appearance, suggesting it as a foundation for incorporating physics and sound.

### Details

* **Repository Setup and Collaboration** David Clement and Aaron Hilton initiated the setup of a new GitHub repository, which Aaron Hilton made public to avoid complexities related to private repository seats ([00:16:45](?tab=t.l4sbz8sbdhyl#heading=h.dhis8mj3rhpv)). David Clement, whose username is david-clment, confirmed their identity ([00:15:34](?tab=t.l4sbz8sbdhyl#heading=h.dgfzcplbsx8w)) and Aaron Hilton added them as a maintainer collaborator using David Clement's email, which was sent via WhatsApp ([00:16:45](?tab=t.l4sbz8sbdhyl#heading=h.dhis8mj3rhpv)). David Clement accepted the invitation to the digital dojo sandbox repo ([00:17:57](?tab=t.l4sbz8sbdhyl#heading=h.teuijbv5tte1)).

* **Folder Structure and Tools** The discussion covered the initial repository structure, with Aaron Hilton fleshing out a plan including a README, outline, and folder hierarchy ([00:19:23](?tab=t.l4sbz8sbdhyl#heading=h.ojfxjohq304d)). David Clement suggested a "content" folder for media files like meshes, and supported placing meeting notes under a "docs" folder where David Clement anticipates spending significant time ([00:25:18](?tab=t.l4sbz8sbdhyl#heading=h.djredftenex0)). Aaron Hilton decided to keep the folder structure "really, really simple" ([00:27:03](?tab=t.l4sbz8sbdhyl#heading=h.c2zdofw38ggz)), which included getting rid of unnecessary top-level sections like "services," "packages," and "research" ([00:26:15](?tab=t.l4sbz8sbdhyl#heading=h.ql2xow3bk09h)).

* **Flask Server for Prototypes** David Clement explained that they typically create a simple Flask server for prototypes, which could be placed under a "prototypes" folder. This server is used as a central HTTP store for tasks like session management and saving data, and it could also efficiently host web pages spawned from chatbots ([00:27:50](?tab=t.l4sbz8sbdhyl#heading=h.i56z90divxoa)). David Clement also noted that running Flask locally would help with app development and cross-site issues ([00:28:51](?tab=t.l4sbz8sbdhyl#heading=h.bbthkaeiwem2)).

* **Demo of Application Refactor** David Clement gave a demo of a reorganized application, which was refactored based on the recent ability to reconstruct well from videos ([00:28:51](?tab=t.l4sbz8sbdhyl#heading=h.bbthkaeiwem2)). The application centers on creating a pin on a map to drop images or videos, which then produces a reconstruction ([00:30:10](?tab=t.l4sbz8sbdhyl#heading=h.ik4m22h2928d)). This new version simplifies the application by focusing on video-to-reconstruction on a map, eliminating previous geometric complexity ([00:32:45](?tab=t.l4sbz8sbdhyl#heading=h.mf81jb7lq31o)) ([00:34:29](?tab=t.l4sbz8sbdhyl#heading=h.ttx1yn7rq9vr)).

* **Application Features and New Focus** The refactored application uses geolocation data from the pin to initiate reconstruction, includes "shot grids" for viewing 360-degree still images at various points along the camera's trajectory ([00:31:01](?tab=t.l4sbz8sbdhyl#heading=h.y7j8ad4gtscm)), and supports adding annotations along with various geographic coordinate systems (longitude, latitude, What Three Words, eastings, and norings) ([00:32:45](?tab=t.l4sbz8sbdhyl#heading=h.mf81jb7lq31o)). David Clement also highlighted the inclusion of a permalink feature for secure, authenticated hyperlink access ([00:34:29](?tab=t.l4sbz8sbdhyl#heading=h.ttx1yn7rq9vr)). David Clement's business partners have requested a slowdown in new features after this completion to provide a stable product for sale ([00:35:21](?tab=t.l4sbz8sbdhyl#heading=h.4t8lt33pyy1f)).

* **Methods for Generative AI Input** Aaron Hilton and David Clement discussed how to guide a generative model, starting with the idea of providing an example, website reference, or text ([00:37:02](?tab=t.l4sbz8sbdhyl#heading=h.mnu1y47n05xr)). Aaron Hilton brought up VGG backbones as intermediaries for translating image inputs into a descriptive, highly retaining data representation (encoding) that can be fed into AI models. David Clement confirmed VGG is a standard model for image recognition and suggested that these encodings could be directly passed to generative models, which Aaron Hilton confirmed is the case ([00:38:06](?tab=t.l4sbz8sbdhyl#heading=h.coa33cc31dfa)) ([00:40:56](?tab=t.l4sbz8sbdhyl#heading=h.bqm2tkq8ihv3)).

* **Generative World Model Concept** David Clement proposed a concept for generative world modeling based on a non-cumulative, constantly "forgetting" system, like a sliding context window ([00:41:31](?tab=t.l4sbz8sbdhyl#heading=h.oymb87oq3kcc)). This process is envisioned as a "trip" where the user describes the desired environment as they virtually "walk," with the system continually generating counterfactuals until the user issues a "freeze" command to halt generation and allow for fine-detail work ([00:42:44](?tab=t.l4sbz8sbdhyl#heading=h.bvyqu9cwt0ni)) ([00:44:26](?tab=t.l4sbz8sbdhyl#heading=h.fadhlss0eitx)). The world's evolution is linked to spatial movement, mapping the latent space of the encoding onto physical space ([00:43:26](?tab=t.l4sbz8sbdhyl#heading=h.imwybfny31y7)).

* **Technical Approaches for Generation and Alignment** Aaron Hilton mentioned recent world generation papers using diffusion models to constantly generate and update a Gaussian splat cloud efficiently ([00:45:37](?tab=t.l4sbz8sbdhyl#heading=h.o65tzw2t2cjh)). Aaron Hilton shared a link to a pipeline that takes equirectangular maps and spatially aligns them with Agisoft Metashape for use with Lickfield Studio's aligned 360-degree images ([00:46:51](?tab=t.l4sbz8sbdhyl#heading=h.3af9l6pkf4tu)). David Clement summarized the rough loop as a constantly refreshed generative model feeding into a workflow that ends in ephemeral splats, which can be frozen ([00:48:11](?tab=t.l4sbz8sbdhyl#heading=h.n0bwwd6v8dke)).

* **Diffusion Generator Workflow and Context Control** In a diagram drawn on Excalidraw, David Clement outlined a loop involving "context" feeding into a diffusion generator, which then updates the context ([00:54:55](?tab=t.l4sbz8sbdhyl#heading=h.3em1fugeutsl)). Input modalities like text, imagery, sound (mentioning "clap," which is like CLIP for audio ([00:56:45](?tab=t.l4sbz8sbdhyl#heading=h.phmo3olli0jv))), or a file encoding can update the context ([00:54:55](?tab=t.l4sbz8sbdhyl#heading=h.3em1fugeutsl)). Aaron Hilton suggested using a Segments Anything Model (SAM) to create an "isolation mask" that allows the diffusion generator to regenerate content in a targeted, masked area from a clean context ([00:57:48](?tab=t.l4sbz8sbdhyl#heading=h.6hik6axgut1v)). David Clement agreed, suggesting the mask would also be controlled by a command interpreter from voice input (VAD), which could also update the mask ([00:59:39](?tab=t.l4sbz8sbdhyl#heading=h.9fq6xmtatk8d)).

* **Diffusion Generator Control Mechanisms** Aaron Hilton and David Clement discussed implementing control mechanisms for the diffusion generator using MCP endpoints ([01:02:42](?tab=t.l4sbz8sbdhyl#heading=h.hhm4p7vjmt5v)). David Clement suggested that these controls include the ability to "stop," "restrict," "mask," and generate text to provide context ([01:01:37](?tab=t.l4sbz8sbdhyl#heading=h.rmbeebxblnv8)). Aaron Hilton agreed that the context, mask, and diffusion generator could all be MCP endpoints ([01:02:42](?tab=t.l4sbz8sbdhyl#heading=h.hhm4p7vjmt5v)).

* **Context Input and Generation Loop** The participants discussed how image input becomes context for the diffusion generator, with David Clement giving the example of dragging and dropping a picture to influence the generation ([01:02:42](?tab=t.l4sbz8sbdhyl#heading=h.hhm4p7vjmt5v)). David Clement also raised the question of whether the diffusion generator needs its own agent or if it functions as an observer of the context. The conversation also touched upon how text descriptions are pushed into the context ([01:03:47](?tab=t.l4sbz8sbdhyl#heading=h.d9x53yv6m5io)) ([01:08:46](?tab=t.l4sbz8sbdhyl#heading=h.adgqpri1377b)).

* **Masking and Refinement Hierarchy** Aaron Hilton suggested using "masked generation" and the Segment Anything Model (SAM) to focus generation on subsets of an image ([01:04:50](?tab=t.l4sbz8sbdhyl#heading=h.aitp7xtkmf45)). David Clement proposed structuring the scene as a graph or a DAG, where masks define a "categorical structure" or "context hierarchy" ([01:05:45](?tab=t.l4sbz8sbdhyl#heading=h.w2rq7ne1ajda)). This hierarchy would enable granular refinement, allowing descriptions to affect specific elements like a frog's band-aid without impacting the background mailbox ([01:06:37](?tab=t.l4sbz8sbdhyl#heading=h.mzv4dyxwnasw)).

* **Persistence and Context Management** David Clement emphasized the need to manage object persistence, suggesting that information about a specific element, such as a frog having a hat and a limp, should be maintained as part of the context, possibly as a JSON package ([01:08:46](?tab=t.l4sbz8sbdhyl#heading=h.adgqpri1377b)). Aaron Hilton agreed that context maintenance is necessary and brought up the concept of a "Laura," or low-rank adaptation, for creating descriptive proxies that ensure consistency in image generation ([01:09:48](?tab=t.l4sbz8sbdhyl#heading=h.65rywljqcvua)).

* **Lauras and CLIP for Consistency** The discussion compared Lauras (low-rank adaptation) to CLIP (Contrastive Language-Image Pre-training) encoding for maintaining consistency ([01:11:22](?tab=t.l4sbz8sbdhyl#heading=h.ucqkm5o4b2mq)) ([01:15:31](?tab=t.l4sbz8sbdhyl#heading=h.fvzf958d8945)). David Clement asked if a Laura model provides context, and Aaron Hilton confirmed that using a Laura serves as a base representation fed back in as context ([01:13:43](?tab=t.l4sbz8sbdhyl#heading=h.9yofzomvwexc)). They concluded that Lauras and CLIP encoding might be talking about the same mechanism for isolating and encoding relevant features to maintain generation consistency ([01:15:31](?tab=t.l4sbz8sbdhyl#heading=h.fvzf958d8945)).

* **Conceptual Framework: Nested Causal Niches** David Clement introduced a theoretical framework based on "nested causal niches," sharing a document on "The architecture of nested causal niches" which synthesizes Shannon entropy, statistical mechanics, and category theory ([01:17:06](?tab=t.l4sbz8sbdhyl#heading=h.f456j7p75w5l)). They related this concept to the image generation problem, stating that objects within a scene represent "microstates" or niches, and that describing something small involves path-tracing through a context hierarchy ([01:19:35](?tab=t.l4sbz8sbdhyl#heading=h.p0ay55v8ilcm)) ([01:21:34](?tab=t.l4sbz8sbdhyl#heading=h.2cmdd4mew33u)).

* **Challenges with Context and Forgetting** David Clement discussed the inherent challenge of managing context in language models, stating that a perfect context is unattainable and systems must cope with the reality of incomplete information ([01:22:51](?tab=t.l4sbz8sbdhyl#heading=h.fae0yl2u7y1k)). They highlighted the issue of LMs being unable to forget information, resulting in "sticky ideas" that can dominate the conversation ([01:23:45](?tab=t.l4sbz8sbdhyl#heading=h.ot5qlb193yrq)). This led to a brief discussion on building a "community of these \[localized\] things" or niches to prevent a single idea from dominating the system ([01:24:35](?tab=t.l4sbz8sbdhyl#heading=h.x7gnnhdltghg)).

* **Steerable Diffusion and Ooxals** The participants discussed the goal of building a "steerable diffusion generator that's constantly running". Aaron Hilton suggested looking into SAM 3D and Trellis 2 for 3D generation from image context ([01:27:32](?tab=t.l4sbz8sbdhyl#heading=h.wi2dptuczbq)). David Clement expressed interest in Trellis 2's potential to generate 3D objects from images ([01:28:32](?tab=t.l4sbz8sbdhyl#heading=h.zgxdkofws4yo)). Aaron Hilton then introduced the concept of an "omnivoxal representation" (ooxals) from the Trellis 2 paper as a scalable and sparse compression of active spatial context ([01:29:13](?tab=t.l4sbz8sbdhyl#heading=h.p9lle0i3oz0z)).

* **Ooxals as a Foundation for Physics and Sound** Aaron Hilton highlighted the benefits of the ovoxal representation, noting that it incorporates geometry and appearance information and solves for sophisticated material parameters, making it more fundamental than splats, which only handle appearance ([01:31:18](?tab=t.l4sbz8sbdhyl#heading=h.xo4zbw52lkyz)). They suggested that ooxals could serve as a good foundation for incorporating physics and sound into the spatial context. David Clement was pleased to note that this system uses a Sparse Compression VAE, which aligns with their existing work, and committed to reading up on ooxals ([01:32:21](?tab=t.l4sbz8sbdhyl#heading=h.8wahi4tkr6pf)).

### Suggested next steps

- [ ] Aaron Hilton will find out more about the advanced generators and double-check on passing the VGG directly to the generator.  
- [ ] David Clement will look at Mimiputs' workflows in more detail later.  
- [ ] David Clement will do some reading this week to perform all the conceptual stuff at this point in time.  
- [ ] David Clement will send Aaron Hilton the PDF document on the architecture of nested causal niches and the link to the online course called statistical rethinking.  
- [ ] Aaron Hilton will push some changes and get the base started.

*You should review Gemini's notes to make sure they're accurate. [Get tips and learn how Gemini takes notes](https://support.google.com/meet/answer/14754931)*

*Please provide feedback about using Gemini to take notes in a [short survey.](https://google.qualtrics.com/jfe/form/SV_9vK3UZEaIQKKE7A?confid=5Y42LiC2Se3yOVFnj2AiDxIROAIIigIgABgECA&detailid=standard)*